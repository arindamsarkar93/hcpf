{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "from edward.models import Poisson,Gamma\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper_func\n",
    "import math\n",
    "import models\n",
    "import scipy.special as sp\n",
    "from scipy.misc import logsumexp\n",
    "import gc\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = 'bibx' \n",
    "# full_X1,x1,test_mask1 = helper_func.load_data(dataset)\n",
    "# dataset = 'biby' \n",
    "# full_X2,x2,test_mask2 = helper_func.load_data(dataset)\n",
    "# result_folder = \"dual_bibtex\"\n",
    "# metric = 'mae'\n",
    "#x1 = full_X1      #for multilable\n",
    "#x2 = full_X2    # for multilable\n",
    "x1,x2,_,_ = helper_func.load_data(\"multi_bibtex\")\n",
    "users = x1.shape[0]\n",
    "items1 = x1.shape[1]\n",
    "items2 = x2.shape[1]\n",
    "train_non_zero_indices1 = helper_func.non_zero_entries(x1)\n",
    "train_non_zero_indices2 = helper_func.non_zero_entries(x2)\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000000\n",
    "epochs += 1\n",
    "test_every = 100000\n",
    "no_samples_mle = 5000\n",
    "no_sample_inf = 20\n",
    "k = 50\n",
    "n_trunc = 10;\n",
    "param1 = models.poisson_response(users,items1,n_trunc);  # 'ztp' or 'normal'\n",
    "param2 = models.poisson_response(users,items2,n_trunc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varpi = 0.1 #looks like 'w^bar' or omega bar\n",
    "sparsity1 = 1.0 - float(len(train_non_zero_indices1))/(users*items1)\n",
    "em1 = -np.log(sparsity1)\n",
    "emsq1 = np.sqrt(em1/k)\n",
    "sparsity2 = 1.0 - float(len(train_non_zero_indices2))/(users*items2)\n",
    "em2 = -np.log(sparsity2)\n",
    "emsq2 = np.sqrt(em2/k)\n",
    "\n",
    "varrho = 0.1 # looks like mirror inverted eta1 = varrho * emsq1  #looks like n\n",
    "zeta1 = varpi *emsq1 #looks like mirror inverted cq\n",
    "rho =  varrho * varrho  #looks like p\n",
    "omega = varpi * varpi #looks like w\n",
    "\n",
    "emsq = 1.0 - (float(len(train_non_zero_indices1)) + float(len(train_non_zero_indices2)))/((users*items1)+(users*items2))\n",
    "emsq = -np.log(emsq)\n",
    "emsq = np.sqrt(emsq/k)\n",
    "\n",
    "eta = varrho * emsq  #looks like n\n",
    "\n",
    "zeta1 = varpi *emsq1 #looks like mirror inverted c\n",
    "zeta2 = varpi *emsq2 #looks like mirror inverted c\n",
    "\n",
    "xi = 0.7\n",
    "tau = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_user = np.ones(shape=users)*tau\n",
    "t_item1 = np.ones(shape=items1)*tau\n",
    "t_item2 = np.ones(shape=items2)*tau\n",
    "\n",
    "a_s = np.ones(shape=[users,k])*eta\n",
    "bs = np.ones(shape=[users,k])*varrho\n",
    "ar =  np.ones(shape=users)*(rho+k*eta)   # not fixed in the original code\n",
    "br = np.ones(shape=users)*(rho/varrho)\n",
    "\n",
    "av1 = np.ones(shape=[items1,k])*zeta1\n",
    "bv1 = np.ones(shape=[items1,k])*varpi\n",
    "aw1 = np.ones(shape=items1)*(omega+k*zeta1)  # not fixed in the original code\n",
    "bw1 = np.ones(shape=items1)*(omega/varpi)\n",
    "\n",
    "av2 = np.ones(shape=[items2,k])*zeta2\n",
    "bv2 = np.ones(shape=[items2,k])*varpi\n",
    "aw2 = np.ones(shape=items2)*(omega+k*zeta2)  # not fixed in the original code\n",
    "bw2 = np.ones(shape=items2)*(omega/varpi)\n",
    "\n",
    "varphi = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1.mle_update(train_non_zero_indices1,x1,no_samples_mle)\n",
    "param2.mle_update(train_non_zero_indices2,x2,no_samples_mle)\n",
    "del train_non_zero_indices1\n",
    "del train_non_zero_indices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n"
     ]
    }
   ],
   "source": [
    "curr_iter  = 0\n",
    "while curr_iter <= epochs:\n",
    "    curr_iter += 1\n",
    "    u = np.random.randint(low=0,high=users,dtype='int64')\n",
    "    i1 = np.random.randint(low=0,high=items1,dtype='int64')\n",
    "    i2 = np.random.randint(low=0,high=items2,dtype='int64')\n",
    "    tu = np.power(t_user[u],-xi)\n",
    "    ti1 = np.power(t_item1[i1],-xi)\n",
    "    ti2 = np.power(t_item2[i2],-xi)\n",
    "    \n",
    "    br[u] = (1.0-tu)*br[u] + tu*(rho/varrho + np.sum(a_s[u,:]/bs[u,:]))\n",
    "    bs[u,:] = (1.0-tu)*bs[u,:] + tu*(ar[u]/br[u] + items1*(av1[i1,:]/bv1[i1,:]) + items2*(av2[i2,:]/bv2[i2,:]))\n",
    "    \n",
    "    bw1[i1] = (1.0-ti1)*bw1[i1] + ti1*(omega/varpi + np.sum(av1[i1,:]/bv1[i1,:]))\n",
    "    bv1[i1,:] = (1.0-ti1)*bv1[i1,:] + ti1*(aw1[i1]/bw1[i1] + users*(a_s[u,:]/bs[u,:]))\n",
    "    \n",
    "    bw2[i2] = (1.0-ti2)*bw2[i2] + ti2*(omega/varpi + np.sum(av2[i2,:]/bv2[i2,:]))\n",
    "    bv2[i2,:] = (1.0-ti2)*bv2[i2,:] + ti2*(aw2[i2]/bw2[i2] + users*(a_s[u,:]/bs[u,:]))\n",
    "    \n",
    "    if x1[u,i1]==0:\n",
    "        av1[i1,:] = (1.0-ti1)*av1[i1,:] + ti1*zeta1\n",
    "        a_s_i1 = 0.0\n",
    "    else:\n",
    "        A_ui1 = np.sum((a_s[u,:]*av1[i1,:])/(bs[u,:]*bv1[i1,:]))\n",
    "        en1 = param1.expectation(x1[u,i1],A_ui1,n_trunc)\n",
    "        varphi[:]= sp.digamma(a_s[u,:])-np.log(bs[u,:])+sp.digamma(av1[i1,:])-np.log(bv1[i1,:])\n",
    "        log_norm = logsumexp(varphi[:])\n",
    "        varphi[:] = np.exp(varphi[:]-log_norm)\n",
    "        av1[i1,:] = (1.0-ti1)*av1[i1,:] + ti1*(zeta1+users*en1*varphi[:])\n",
    "        a_s_i1 = items1*en1*varphi[:]\n",
    "        \n",
    "    if x2[u,i2]==0:\n",
    "        av2[i2,:] = (1.0-ti2)*av2[i2,:] + ti2*zeta2\n",
    "        a_s_i2 = 0.0\n",
    "    else:\n",
    "        A_ui2 = np.sum((a_s[u,:]*av2[i2,:])/(bs[u,:]*bv2[i2,:]))\n",
    "        en2 = param2.expectation(x2[u,i2],A_ui2,n_trunc)\n",
    "        varphi[:]= sp.digamma(a_s[u,:])-np.log(bs[u,:])+sp.digamma(av2[i2,:])-np.log(bv2[i2,:])\n",
    "        log_norm = logsumexp(varphi[:])\n",
    "        varphi[:] = np.exp(varphi[:]-log_norm)\n",
    "        av2[i2,:] = (1.0-ti2)*av2[i2,:] + ti2*(zeta2+users*en2*varphi[:])\n",
    "        a_s_i2 = items2*en2*varphi[:]\n",
    "\n",
    "\n",
    "    a_s[u,:] = (1.0-tu)*a_s[u,:] + tu*(eta + a_s_i1 + a_s_i2)\n",
    "\n",
    "    \n",
    "    t_user[u] += 1.0\n",
    "    t_item1[i1] += 1.0\n",
    "    t_item2[i2] += 1.0\n",
    "    \n",
    "    if curr_iter%test_every == 0:\n",
    "        print curr_iter\n",
    "#         q_theta = Gamma(a_s,bs)\n",
    "#         q_beta1 = Gamma(np.transpose(av1),np.transpose(bv1))\n",
    "#         q_beta2 = Gamma(np.transpose(av2),np.transpose(bv2))\n",
    "#         theta_sample = q_theta.sample(no_sample_inf).eval()\n",
    "#         beta1_sample = q_beta1.sample(no_sample_inf).eval()\n",
    "#         beta2_sample = q_beta2.sample(no_sample_inf).eval()\n",
    "#         score.append(helper_func.check(param1,theta_sample,beta1_sample,test_mask1,full_X1,metric=metric) \\\n",
    "#                     +helper_func.check(param2,theta_sample,beta2_sample,test_mask2,full_X2,metric=metric))\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print helper_func.auc_score(test_mask1,full_X1,a_s,av1,bs,bv1)\n",
    "# print helper_func.auc_score(test_mask2,full_X2,a_s,av1,bs,bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_theta = Gamma(a_s,bs)\n",
    "theta_sample = q_theta.sample(no_sample_inf+30).eval()\n",
    "theta = np.zeros(shape=[users,k])\n",
    "for i in range(0,no_sample_inf+30):\n",
    "    theta += theta_sample[i]\n",
    "theta /= (no_sample_inf+30)\n",
    "\n",
    "q_beta1 = Gamma(np.transpose(av1),np.transpose(bv1))\n",
    "beta1_sample = q_beta1.sample(no_sample_inf+30).eval()\n",
    "beta1 = np.zeros(shape=[k,items1])\n",
    "for i in range(0,no_sample_inf+30):\n",
    "    beta1 += beta1_sample[i]\n",
    "beta1 /= (no_sample_inf+30)\n",
    "\n",
    "q_beta2 = Gamma(np.transpose(av2),np.transpose(bv2))\n",
    "beta2_sample = q_beta2.sample(no_sample_inf+30).eval()\n",
    "beta2 = np.zeros(shape=[k,items2])\n",
    "for i in range(0,no_sample_inf+30):\n",
    "    beta2 += beta2_sample[i]\n",
    "beta2 /= (no_sample_inf+30)\n",
    "\n",
    "to_save = [theta,beta1,beta2]\n",
    "PIK = \"../models/bibtex_po_po_\"+str(k)+\".dat\"\n",
    "with open(PIK, \"wb\") as f:\n",
    "    pickle.dump(to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(score)\n",
    "# plt.show()\n",
    "#print min(score)\n",
    "# np.savetxt('../results/'+result_folder+'/'+'hcpf_po_dual_'+metric+'_'+str(k)+'.txt',np.array(score))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bml]",
   "language": "python",
   "name": "conda-env-bml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
